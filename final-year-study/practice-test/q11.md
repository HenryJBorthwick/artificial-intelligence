## belief networks and probabilistic theory

### question
```
Complete the following statements.

Compared with using a single joint distribution table:

a belief net typically requires Answer 1 free parameters;

a belief net typically requires Answer 2 training data to estimate the probability values;

a belief net has Answer 3 (random) variables;

running inference by enumeration on a belief net takes Answer 4 time (assuming that the time required to compute joint_prob(network, assignment) is negligible).

```

#### answer 1 and reasoning
- fewer, joint distribution specifies probabilities for all possible combinations of variables, the belief network the conditional probabilities of each variables given its parent network.
- Joint Distribution: 2^n - 1, where n is number of variables
- Belief Network: n * 2^k, where k is maximum number of parents a node has

#### answer 2 and reasoning
- less, number of free parameters directly impacts the amount of training data needed. Since belief networks require less free parameters because of conditional dependencies

#### answer 3 and reasoning
- same, joint distribution and belief networks represent the same number of random variables
- Belief networks just organizes them differently to exploit conditional independencies

#### answer 4 and reasoning
- less/about the same, inference by enumeration summing all possible assignments of variables. 
- Joint distribution this is exponential
- Belief network only worse case is exponential or np-hard, network structure allows for more efficient computations


#### context for question
- Joint probability distribution over set of random variables provides probability for every possible combination of variable values.
- For n binary variables, this requires 2^n probabilities. Each variable can take 2 values and there are n variables.
- Because all probabilities sum to 1, the number of free parameters (independent probabilities we need to specify) is 2^n - 1

- Belief network graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph.
- Each node in graph represent a random variable, edges represent the conditional dependencies between variables.
- Belief networks uses the conditional independence between variables to reduce the number of free parameters need to specify the join distribution.



**Additional Concepts and Potential Exam Questions**

- **Impact of Network Structure**: How does the topology of a belief network (e.g., the number of parents per node) affect the number of free parameters and the complexity of inference?

  *Explanation*: The more parents a node has, the more conditional probabilities need to be specified, increasing the number of free parameters and potentially the complexity of inference.

- **Conditional Independence**: Explain how conditional independence assumptions in a belief network reduce the number of parameters.

  *Explanation*: Conditional independence allows us to break down the joint probability into smaller, conditional probabilities, reducing the number of parameters from exponential to linear or polynomial in the number of variables.

- **Inference Algorithms**: What are some algorithms used for inference in belief networks, and how do they improve upon inference by enumeration?

  *Explanation*: Algorithms like Variable Elimination, Belief Propagation, and Monte Carlo methods can perform inference more efficiently by exploiting the network's structure.

- **Real-World Applications**: Provide examples of how belief networks are used in practice (e.g., medical diagnosis, machine learning).

- **Limitations of Belief Networks**: Discuss scenarios where belief networks might not provide significant advantages over joint distributions.
