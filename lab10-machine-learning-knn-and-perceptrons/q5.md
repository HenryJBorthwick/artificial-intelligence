# binary classification

## question
Consider a binary classification problem (i.e. there are two classes in the domain) where each object is represented by 2 numeric values (2 features). We are using a single perceptron as a classifier for this domain and want to learn its parameters. The weight update rule is w←w+ηx(t−y). We use the following configuration.

```
weights = [-0.5, 0.5]
bias = -0.5
learning_rate = 0.5

examples = [
    ([1, 1],   0),    # index 0 (first example)
    ([2, 0],   1),
    ([1, -1],  0),
    ([-1, -1], 1),
    ([-2, 0],  0),
    ([-1, 1],  1),
]
```

Answer the following with numeric values:
After seeing the example at index 0, the value of the weight vector is [BLANK,BLANK] and the value of bias is BLANK.

After seeing the example at index 1, the value of the weight vector is [BLANK,BLANK] and the value of bias is BLANK.

After seeing the example at index 2, the value of the weight vector is [BLANK,BLANK] and the value of bias is BLANK.

## working
- INDEX 0 
  - Information
    - Input, x = [1,1]
    - Target output, t = 0
    - Initial weighs, w = [-0.5, 0.5]
    - Initial Bias, b = -0.5

  - Compute Activation
    - activation = w * x + b = (-0.5*1) + (0.5*1) + (-0.5) = -0.5

  - Determine Predicted Outcome (y)
    - Activation < 0 ?
    - -0.5 < 0, y = 0

  - Calculate Error
    - t - y = 0 - 0 = 0

  - Update Weights and Bias
    - Since error = 0, then weights/bias remain unchanged
    - Updated weights = [-0.5, 0.5]
    - Updated bias = -0.5

- INDEX 1
  - Information
    - Input x = [2,0]
    - Target output t = 1
    - Initial weights w = [-0.5, 0.5]
    - Initial bias b = -0.5
    - Learning rate n = 0.5
  - Compute Activation
    - w * x + b = (-0.5*2) + (0.5*0) + -0.5 = -1.5
  - Determine predicted output
    - activation < 0 ?
    - -1.5 < 0, y = 0
  - Calculate Error
    - t - y = 1 - 0 = 1
  - Update weights and bias
    - error = 1 therefore we do update weights and bias
    - Updated weight, w = n * x * (t - y) = (0.5 * 2 * 1) + (0.5 * 0 * 1) = [1.0, 0.0], original wight + new weight = [-0.5, 0.5] + [1.0, 0.0] = [0.5, 0.5]
    - Updated bias, b = n * (t - y) = 0.5 * 1 = 0.5, original bias + new bias = -0.5 +0.5 = 0.0

- INDEX 2
  - Information
    - Input, x = [1, -1]
    - Target output, t = 0
    - Current weights, w = [0.5, 0.5]
    - Current bias, b = 0.0
  - Compute activation
    - activation = weight * input + bias = (0.5 * 1) + (0.5 * -1) + 0.0 = 0.0
  - Determine predicted output
    - Is activation less than 0?
    - y = 1 as activation is greater than or equal to 0
  - Calculate Error
    - Error = Target output - predicted output = 0 - 1 = -1
  - Updated weights and bias
    - Updated weight1, w = current weight + learning rate * input * error rate = 0.5 + (0.5 * 1 * -1) = 0.0
    - Updated weight2, w = current weight + learning rate * input * error rate = 0.5 + (0.5 *-1 * -1) = 1.0
  - Updated bias
    - current bias + learning rate * error rate = 0.0 + (0.5 * -1) = -0.5